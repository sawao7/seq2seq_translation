# seq2seq_translation
### 目的
 唐突だが、僕は言語の壁がない世界を作りたい。言葉が違うというだけで、人同士が考えを伝えることすらできない。こんな理不尽がまかり通って良いのだろうか。
 そこで、色々試行錯誤の末、翻訳アプリがあればいいのではないかという結論に至った。そして今現在あるgoogle翻訳を参照すると、お世辞にも人間のように訳せているとは言えない。
 普通ならそこで諦めるもしくは他人に任せるところなのだろうが、僕には別の考えが頭に浮かんだ。
 「僕が作ろう。最高の翻訳アプリを」
### 手法
  翻訳アプリを作る上で手法は山のようにあるが、今回はseq2seqというRNNを改良したモデルを採用することにする。
  ①データを集める(今回は日本語<=>英語の翻訳を行いたいので、大量にデータをwebから集めた。webスクレイピングを使い、辞書から例文を集める方法も使用したが、結局は田中コーパスを使用することになった)
  ②日本語をMecabを用い、形態素解析する。
  ③seq2seqをKerasを用い作成し、google colaboratryで学習。(12時間が最大だったので、約10時間ぐらい学習した)
  ④BLEU関数を用いてモデルの評価。
### 結果
  結果は、google翻訳の精度にははるか及ばず、およそ30が最高だった。(BLEUスコアでは、一般に40を超えると高品質のモデルとされる。)
  しかし、今回データ収集からモデルの学習、評価まで一通りの流れを一人で完了することができたため、この経験を活かして今後も挑戦していくつもりである。次回は、transformerを用いてより精度の高いモデルの作成を目指す。
  
 
